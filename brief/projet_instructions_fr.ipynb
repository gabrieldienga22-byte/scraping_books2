{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a65c22e",
   "metadata": {},
   "source": [
    "# üìö Projet ‚Äì Books to Scrape\n",
    "\n",
    "## ‚è±Ô∏è Temps Estim√© : **300 minutes (5 heures)**\n",
    "\n",
    "Ce projet vous guidera dans la cr√©ation d‚Äôun **web scraper** pour le site [Books to Scrape](https://books.toscrape.com/). Il est con√ßu comme un exercice pratique pour s‚Äôentra√Æner avec **Python, requests, Pandas et l‚Äôanalyse de donn√©es**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fcdfc2",
   "metadata": {},
   "source": [
    "## üéØ Contexte\n",
    "\n",
    "L‚Äô√©quipe marketing d‚Äôune librairie en ligne souhaite mieux comprendre son catalogue. Elle veut collecter des informations sur tous les livres, analyser les cat√©gories, les prix, les notes et la disponibilit√© en stock.\n",
    "\n",
    "En tant que data scientist, votre mission est de **scraper le site web** et de livrer des jeux de donn√©es structur√©s ainsi que des premiers insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b74b63",
   "metadata": {},
   "source": [
    "## ‚úÖ Objectifs\n",
    "\n",
    "1. Scraper le site [Books to Scrape](https://books.toscrape.com/)\n",
    "2. Extraire pour chaque livre :\n",
    "   - Titre\n",
    "   - Prix\n",
    "   - Disponibilit√© en stock\n",
    "   - Note\n",
    "   - URL du produit\n",
    "   - URL de l‚Äôimage\n",
    "   - UPC\n",
    "   - Cat√©gorie\n",
    "3. G√©rer la **pagination** sur toutes les pages\n",
    "4. Sauvegarder les r√©sultats dans **un CSV par cat√©gorie**\n",
    "5. T√©l√©charger les images des couvertures de livres dans des dossiers par cat√©gorie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df80118e",
   "metadata": {},
   "source": [
    "## üì¶ Livrables\n",
    "\n",
    "- Fichiers CSV : `outputs/csv/category_<slug>.csv`\n",
    "- Images : `outputs/images/<category>/<upc>_<slug-title>.jpg`\n",
    "- Optionnel : Un notebook de nettotage et d‚Äôexploration qui analyse les prix, notes et stocks avec Pandas et Quelques visualisation √† r√©aliser avec les packages que vous pr√©f√©r√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964718c",
   "metadata": {},
   "source": [
    "## üõ† √âtapes sugg√©r√©es\n",
    "\n",
    "1. Commencez par scraper **une page produit** et extraire les champs demand√©s\n",
    "2. √âtendez votre code √† **une cat√©gorie** (gestion de plusieurs pages)\n",
    "3. G√©n√©ralisez votre scraper √† **toutes les cat√©gories**\n",
    "4. Sauvegardez les r√©sultats dans des fichiers CSV\n",
    "5. √âtendez le scraper pour aussi **t√©l√©charger les images**\n",
    "6. (Optionnel) Explorez le dataset avec Pandas (prix moyen par cat√©gorie, distribution des notes, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ffcdb",
   "metadata": {},
   "source": [
    "# üõ† √âtapes d√©taill√©es\n",
    "\n",
    "## üü¢ Phase 1 ‚Äì Construire pas √† pas (dans un seul script au d√©but)\n",
    "1. **R√©cup√©rer une page** ‚Üí utiliser `requests` pour t√©l√©charger le HTML.  \n",
    "2. **Extraire les titres** ‚Üí avec `Selector`, r√©cup√©rer les noms des livres sur la page d‚Äôaccueil.  \n",
    "3. **Extraire les d√©tails** ‚Üí ouvrir la page d‚Äôun livre et extraire :\n",
    "   - titre  \n",
    "   - prix  \n",
    "   - disponibilit√© en stock  \n",
    "   - note (rating)  \n",
    "   - UPC  \n",
    "   - **URL de l‚Äôimage** (utiliser `.css(\"img::attr(src)\")` + `urljoin` pour obtenir le lien absolu)  \n",
    "4. **G√©rer une cat√©gorie** ‚Üí collecter toutes les URLs de livres dans une page de cat√©gorie.  \n",
    "5. **G√©rer plusieurs pages** ‚Üí suivre le bouton `\"li.next a\"` jusqu‚Äô√† ce qu‚Äôil n‚Äôy en ait plus.  \n",
    "6. **Sauvegarder les r√©sultats** ‚Üí √©crire les r√©sultats dans un fichier CSV (`outputs/csv/category_<name>.csv`).  \n",
    "7. **T√©l√©charger les images** ‚Üí utiliser l‚ÄôURL de l‚Äôimage pour la t√©l√©charger avec `requests` :\n",
    "   - Chemin : `outputs/images/<categorie>/<upc>_<slug-title>.jpg`  \n",
    "8. **G√©rer plusieurs cat√©gories** ‚Üí boucler sur toutes les cat√©gories depuis la page d‚Äôaccueil.  \n",
    "\n",
    "\n",
    "## üü° Phase 2 ‚Äì Organiser le projet\n",
    "Une fois que le code fonctionne, s√©parer en plusieurs fichiers :  \n",
    "- `parsers.py` ‚Üí fonctions de scraping (par ex. `parse_list_page`, `parse_product_page`, `get_category_links`)  \n",
    "- `utils.py` ‚Üí fonctions utilitaires (par ex. `write_csv`, `download_file`, `ensure_dir`)  \n",
    "- `settings.py` ‚Üí constantes (`BASE_URL`, `HEADERS`, `DEFAULT_DELAY`, `TIMEOUT`)  \n",
    "- `scrape.py` ‚Üí script principal (seulement `main()` + argparse), appelle les fonctions des autres fichiers  \n",
    "\n",
    "\n",
    "## üîµ Phase 3 ‚Äì Automatiser avec la ligne de commande (CLI)\n",
    "Ajouter des **options argparse** dans `scrape.py` :  \n",
    "- `--categories Travel,Poetry` ‚Üí scraper seulement certaines cat√©gories  \n",
    "- `--max-pages 1` ‚Üí limiter le scraping pour des tests rapides  \n",
    "- `--delay 1` ‚Üí ajouter un d√©lai entre les requ√™tes  \n",
    "- `--outdir outputs` ‚Üí changer le dossier de sortie  \n",
    "\n",
    "Exemple d‚Äôutilisation :\n",
    "```bash\n",
    "python scrape.py --categories Travel --max-pages 1\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T16:14:59.179103Z",
     "start_time": "2025-10-22T16:14:59.172844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from parsel import Selector\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# URL de base\n",
    "url = \"https://books.toscrape.com/\"\n"
   ],
   "id": "3f162b3e3f89c5f5",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T16:15:02.004828Z",
     "start_time": "2025-10-22T16:15:01.141516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Faire la requ√™te\n",
    "r = requests.get(url)\n",
    "print(\"Status code:\", r.status_code)\n",
    "\n",
    "# Cr√©er le s√©lecteur\n",
    "response = Selector(text=r.text)\n"
   ],
   "id": "ac32f0c9ccda4510",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T16:15:03.057939Z",
     "start_time": "2025-10-22T16:15:03.049936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tester sur un livre\n",
    "book = response.css('article.product_pod')[0]\n",
    "\n",
    "# Titre\n",
    "title = book.css('h3 a::attr(title)').get()\n",
    "print(\"Titre:\", title)\n",
    "\n",
    "# Prix\n",
    "price = book.css('p.price_color::text').get()\n",
    "print(\"Prix:\", price)\n",
    "\n",
    "# Note (rating)\n",
    "rating_class = book.css('p.star-rating::attr(class)').get()\n",
    "print(\"Rating class:\", rating_class)\n",
    "\n",
    "# Disponibilit√© (nettoy√©e)\n",
    "availability = book.css('p.instock.availability::text').getall()\n",
    "availability_clean = [a.strip() for a in availability if a.strip()]\n",
    "print(\"Disponibilit√©:\", availability_clean)\n",
    "\n",
    "# URL du livre\n",
    "book_url = book.css('h3 a::attr(href)').get()\n",
    "print(\"URL:\", book_url)\n",
    "\n",
    "# URL de l'image\n",
    "image_url = book.css('div.image_container img::attr(src)').get()\n",
    "print(\"Image:\", image_url)\n"
   ],
   "id": "41bdd21c09a8b6fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titre: A Light in the Attic\n",
      "Prix: √Ç¬£51.77\n",
      "Rating class: star-rating Three\n",
      "Disponibilit√©: ['In stock']\n",
      "URL: catalogue/a-light-in-the-attic_1000/index.html\n",
      "Image: media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T16:15:06.082945Z",
     "start_time": "2025-10-22T16:15:06.079375Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cd25b61ac80b4446",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 3 √©toiles\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T16:15:32.087051Z",
     "start_time": "2025-10-22T16:15:32.075432Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bc01c18f27cdfc36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de livres sur la page: 20\n",
      "Total livres extraits: 20\n",
      "\n",
      "Dix premier livres:\n",
      "[{'title': 'A Light in the Attic', 'price': '√Ç¬£51.77', 'rating': 3, 'in_stock': True, 'url': 'catalogue/a-light-in-the-attic_1000/index.html', 'image': 'media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg'}, {'title': 'Tipping the Velvet', 'price': '√Ç¬£53.74', 'rating': 1, 'in_stock': True, 'url': 'catalogue/tipping-the-velvet_999/index.html', 'image': 'media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg'}, {'title': 'Soumission', 'price': '√Ç¬£50.10', 'rating': 1, 'in_stock': True, 'url': 'catalogue/soumission_998/index.html', 'image': 'media/cache/3e/ef/3eef99c9d9adef34639f510662022830.jpg'}, {'title': 'Sharp Objects', 'price': '√Ç¬£47.82', 'rating': 4, 'in_stock': True, 'url': 'catalogue/sharp-objects_997/index.html', 'image': 'media/cache/32/51/3251cf3a3412f53f339e42cac2134093.jpg'}, {'title': 'Sapiens: A Brief History of Humankind', 'price': '√Ç¬£54.23', 'rating': 5, 'in_stock': True, 'url': 'catalogue/sapiens-a-brief-history-of-humankind_996/index.html', 'image': 'media/cache/be/a5/bea5697f2534a2f86a3ef27b5a8c12a6.jpg'}, {'title': 'The Requiem Red', 'price': '√Ç¬£22.65', 'rating': 1, 'in_stock': True, 'url': 'catalogue/the-requiem-red_995/index.html', 'image': 'media/cache/68/33/68339b4c9bc034267e1da611ab3b34f8.jpg'}, {'title': 'The Dirty Little Secrets of Getting Your Dream Job', 'price': '√Ç¬£33.34', 'rating': 4, 'in_stock': True, 'url': 'catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html', 'image': 'media/cache/92/27/92274a95b7c251fea59a2b8a78275ab4.jpg'}, {'title': 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 'price': '√Ç¬£17.93', 'rating': 3, 'in_stock': True, 'url': 'catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html', 'image': 'media/cache/3d/54/3d54940e57e662c4dd1f3ff00c78cc64.jpg'}, {'title': 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 'price': '√Ç¬£22.60', 'rating': 4, 'in_stock': True, 'url': 'catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html', 'image': 'media/cache/66/88/66883b91f6804b2323c8369331cb7dd1.jpg'}, {'title': 'The Black Maria', 'price': '√Ç¬£52.15', 'rating': 1, 'in_stock': True, 'url': 'catalogue/the-black-maria_991/index.html', 'image': 'media/cache/58/46/5846057e28022268153beff6d352b06c.jpg'}]\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e241ecf32ba7a097"
  },
  {
   "cell_type": "markdown",
   "id": "937efb57",
   "metadata": {},
   "source": [
    "## üü£ Phase 4 ‚Äì Documenter\n",
    "- Cr√©er un fichier `README.md` avec :\n",
    "  - L‚Äôobjectif du projet et son contexte  \n",
    "  - Comment installer les d√©pendances (`pip install -r requirements.txt`)  \n",
    "  - Comment ex√©cuter le scraper  \n",
    "  - Quelques exemples de commandes  \n",
    "\n",
    "\n",
    "## üî¥ Phase 5 ‚Äì Partager\n",
    "- Publier votre projet sur GitHub avec :\n",
    "  - Les fichiers de code (`scrape.py`, `parsers.py`, `utils.py`, `settings.py`)  \n",
    "  - Un exemple de `README.md`  \n",
    "  - Un dossier `outputs/` vide avec un fichier `.gitkeep` pour conserver la structure  \n",
    "\n",
    "\n",
    "## üü† Phase 6 ‚Äì Explorer les donn√©es\n",
    "Ouvrir un **notebook Jupyter** pour analyser les donn√©es extraites :\n",
    "\n",
    "1. **Charger un CSV** avec Pandas :\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   df = pd.read_csv(\"outputs/csv/category_travel.csv\")\n",
    "   df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ba8f6",
   "metadata": {},
   "source": [
    "## üìù Crit√®res d‚Äô√©valuation\n",
    "\n",
    "- üí° Effort et compr√©hension :  \n",
    "  - Je valorise **vos propres essais** plus qu‚Äôun simple copier-coller depuis ChatGPT ou Internet.  \n",
    "  - M√™me un progr√®s partiel, des commentaires clairs dans le code, ou diff√©rentes tentatives montrent un v√©ritable apprentissage.  \n",
    "  - Vous devez √™tre capable d‚Äô**expliquer votre code** lors de la relecture ou de la pr√©sentation.  \n",
    "\n",
    "- üåü Points bonus pour la partie analyse de la donn√©e √† la fin avec un notebook et de la recherche sur itnernet de comment faire des visualisations pertinentes et cr√©ative dans le notebook (vous pouvez explorer la librarie **plotly express**).  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
